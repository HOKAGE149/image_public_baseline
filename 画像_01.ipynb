{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "画像_01.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GUBLGe6rTr65",
        "_wo3l7alT5pV",
        "l_AptYegUOMx"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1koRSLAjtSc1P9e03hSQtdsVbjhbTojTa",
      "authorship_tag": "ABX9TyO06pwHmFh6Ze8L5z64wJpm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HOKAGE149/image_public_baseline/blob/main/%E7%94%BB%E5%83%8F_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VFX46rKKjxK"
      },
      "source": [
        "## まとまってる記事"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KO3orFDIJa-0"
      },
      "source": [
        "https://qiita.com/ground0state/items/c1d705ca2ee329cdfae4\n",
        "\n",
        "https://qiita.com/fam_taro/items/df8656a6c3b277f58781"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxiFRc9cJioK"
      },
      "source": [
        "## インストール"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-SR5Nxi6nmS8",
        "outputId": "f000175c-3122-49c3-cbe8-be0db1486774"
      },
      "source": [
        "from googleapiclient.discovery import build\n",
        "import io, os\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "results = drive_service.files().list(\n",
        "        q=\"name = 'kaggle.json'\", fields=\"files(id)\").execute()\n",
        "kaggle_api_key = results.get('files', [])\n",
        "\n",
        "filename = \"/root/.kaggle/kaggle.json\"\n",
        "os.makedirs(os.path.dirname(filename), exist_ok=True)\n",
        "\n",
        "request = drive_service.files().get_media(fileId=kaggle_api_key[0]['id'])\n",
        "fh = io.FileIO(filename, 'wb')\n",
        "downloader = MediaIoBaseDownload(fh, request)\n",
        "done = False\n",
        "while done is False:\n",
        "    status, done = downloader.next_chunk()\n",
        "    print(\"Download %d%%.\" % int(status.progress() * 100))\n",
        "os.chmod(filename, 600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Download 100%.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1baZN57Jbk1"
      },
      "source": [
        "! pip install --quiet \"scikit-learn\" \"datasets\" \"scipy\" \"torchmetrics\" \"transformers\" \"torch==1.9\" \"pytorch-lightning==1.2.8\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJTYVs9DOSJa"
      },
      "source": [
        "!pip install -q timm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vk-lD5ELO4zt",
        "outputId": "68fe91c1-1acf-4335-f4f2-a0f79b894fb9"
      },
      "source": [
        "!pip uninstall -y albumentations\n",
        "!pip install -q albumentations==0.5.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found existing installation: albumentations 0.5.2\n",
            "Uninstalling albumentations-0.5.2:\n",
            "  Successfully uninstalled albumentations-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7506SJ6OyeK"
      },
      "source": [
        "\n",
        "# !pip install -U git+https://github.com/albu/albumentations > /dev/null \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv-RnrTb_W2e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYHRYuKTJkwo"
      },
      "source": [
        "from datetime import datetime\n",
        "from typing import Optional\n",
        "\n",
        "import datasets\n",
        "import torch\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, seed_everything, Trainer\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import loggers as pl_loggers\n",
        "from pytorch_lightning.loggers.csv_logs import CSVLogger\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import (\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "# ========================================\n",
        "# library\n",
        "# ========================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel,AutoConfig\n",
        "import transformers\n",
        "from transformers import RobertaModel,RobertaTokenizer\n",
        "from transformers import AlbertModel,AlbertTokenizer\n",
        "from transformers import XLNetModel,XLNetTokenizer,XLNetConfig\n",
        "from transformers import DebertaModel, DebertaTokenizer\n",
        "from transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\n",
        "from transformers import BartModel,BertModel,BertTokenizer\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from transformers import MPNetModel,MPNetTokenizer\n",
        "from transformers import FunnelBaseModel,FunnelTokenizer,FunnelModel\n",
        "from transformers import GPT2Model, GPT2Tokenizer, GPT2Config\n",
        "from transformers import T5EncoderModel,T5Tokenizer\n",
        "import logging\n",
        "import sys\n",
        "from contextlib import contextmanager\n",
        "import time\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "import gc\n",
        "from sklearn import model_selection\n",
        "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
        "\n",
        "# Hide Warning\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
        "warnings.filterwarnings('ignore', category=FutureWarning)\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "# Python Libraries\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import glob\n",
        "import math\n",
        "\n",
        "\n",
        "# Visualizations\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import plotly.express as px\n",
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Utilities and Metrics\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Pytorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam, SGD\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "from torch.optim.optimizer import Optimizer, required \n",
        "\n",
        "\n",
        "# Pytorch Lightning\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import seed_everything\n",
        "from pytorch_lightning import Callback\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "# Pytorch Image Models\n",
        "import timm\n",
        "\n",
        "# Image Augmentation Library\n",
        "import albumentations\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from albumentations.core.transforms_interface import DualTransform\n",
        "from albumentations.augmentations import functional as AF\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScNv5j2PJpdL"
      },
      "source": [
        "# %cd '/content/drive/MyDrive/Colab Notebooks/SETI/src'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeXVB4AdKoLZ"
      },
      "source": [
        "!pip install --upgrade -q wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX1SUZmjLKAf",
        "outputId": "16e7508a-c866-496c-c91d-2d5e68954993"
      },
      "source": [
        "# Weights and Biases Tool\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "eNufN8genjHm",
        "outputId": "526ba1f1-20e3-416f-f7bf-9c1e6e440b7f"
      },
      "source": [
        "albumentations.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'0.5.2'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TX5QNBbKpLEj"
      },
      "source": [
        "## データロード30分"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_xXdN1AONhA"
      },
      "source": [
        "# !chmod 600 /root/.kaggle/kaggle.json\n",
        "# !pip uninstall -y kaggle\n",
        "# !pip install --upgrade pip\n",
        "# !pip install kaggle==1.5.6\n",
        "\n",
        "# GCS_DS_PATH = \"gs://kds-06ebe33f115002b87e00190a4afa61624bf9aaf3b7f192044f43ffef\"\n",
        "# !gsutil -m cp -r {GCS_DS_PATH}/\"train\" ."
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLj3MyNTQoSg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z60P9RSIQHDQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyLWl5idvPIc"
      },
      "source": [
        "## config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRX6vYQrRr2j"
      },
      "source": [
        "class dict2(dict): \n",
        "    def __init__(self, *args, **kwargs): \n",
        "        super().__init__(*args, **kwargs) \n",
        "        self.__dict__ = self \n",
        "cfg = dict2({'General': \n",
        "            dict2({'seed': 1996, \n",
        "                  'debug': False, \n",
        "                   'compe_name': 'SETI',\n",
        "                  'project': 'project001', \n",
        "                  'epoch': 10, \n",
        "                  'gpus': 1, \n",
        "                  'multi_gpu_mode': False, \n",
        "                  'fp16': False,\n",
        "                  'amp_level': False,\n",
        "                   'image_size': 320,\n",
        "                   'save_dir': '/content',\n",
        "                   'tb_logger_dir': './lightning_log'\n",
        "                }), \n",
        "          'Data': \n",
        "            dict2({'dataset': \n",
        "                    dict2({'fold': 0,\n",
        "                           'nfolds': 5,\n",
        "                           'test_csv': '/content/drive/MyDrive/Colab Notebooks/SETI/input/sample_submission.csv',\n",
        "                           'train_csv': '/content/drive/MyDrive/Colab Notebooks/SETI/input/train_labels_paths.csv',\n",
        "                           'target_col': 'target'}),\n",
        "                   'dataloader':\n",
        "                    dict2({'train_batch_size': 32,\n",
        "                           'valid_batch_size': 32,\n",
        "                           'test_batch_size': 32,\n",
        "                           'train_num_workers': 8,\n",
        "                           'valid_num_workers': 8,\n",
        "                           'test_num_workers': 8})\n",
        "                    }),\n",
        "          'Model': \n",
        "            dict2({'name': 'efficientnet_b0',\n",
        "                   'pretrained': True,\n",
        "                   'out_features': 1,\n",
        "                   'input_channels': 1,\n",
        "                   }),\n",
        "          'Loss':\n",
        "            dict2({'name': 'AUC'}),\n",
        "          'Optimizer':\n",
        "            dict2({'name': 'AdamW',\n",
        "                   'lr': 1e-3}),\n",
        "          'Scheduler':\n",
        "            dict2({'name': 'CosineAnnealingLR',\n",
        "                   'T_max': 10,\n",
        "                   'min_lr': 1e-6}),\n",
        "          'Augmentation': True\n",
        "})\n",
        "\n",
        "params = {\n",
        "    'seed': 42,\n",
        "    'model': 'efficientnet_b0',\n",
        "    'size' : 320,\n",
        "    'inp_channels': 1,\n",
        "    'lr': 1e-3,\n",
        "    'weight_decay': 1e-6,\n",
        "    'batch_size': 32,\n",
        "    'num_workers' : 8,\n",
        "    'epochs': 5,\n",
        "    'out_features': 1,\n",
        "    'name': 'CosineAnnealingLR',\n",
        "    'T_max': 10,\n",
        "    'min_lr': 1e-6,\n",
        "    'nfolds': 5,\n",
        "    'precision': 16\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_MyJ5qIvgXl"
      },
      "source": [
        "def seed_everything(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    \n",
        "seed_everything(cfg.General.seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Podjv25XTRgM"
      },
      "source": [
        "## Load Train and Test\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eybxwAL6RtRG"
      },
      "source": [
        "import pandas as pd\n",
        "train_dir = ('/content/train')\n",
        "# test_dir = ('../input/seti-breakthrough-listen/test')\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SETI/input/train_labels.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/SETI/input/sample_submission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EdZKw3KtR3UF"
      },
      "source": [
        "def return_filpath(name, folder=train_dir):\n",
        "    path = os.path.join(folder, name[0], f'{name}.npy')\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "XG5G9BIlR47m",
        "outputId": "47482c89-90ef-4a0d-9c71-83163a825e87"
      },
      "source": [
        "train_df['image_path'] = train_df['id'].apply(lambda x: return_filpath(x))\n",
        "# test_df['image_path'] = test_df['id'].apply(lambda x: return_filpath(x, folder=test_dir))\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>image_path</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000799a2b2c42d</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/train/0/0000799a2b2c42d.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>00042890562ff68</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/train/0/00042890562ff68.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0005364cdcb8e5b</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/train/0/0005364cdcb8e5b.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0007a5a46901c56</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/train/0/0007a5a46901c56.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0009283e145448e</td>\n",
              "      <td>0</td>\n",
              "      <td>/content/train/0/0009283e145448e.npy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                id  target                            image_path\n",
              "0  0000799a2b2c42d       0  /content/train/0/0000799a2b2c42d.npy\n",
              "1  00042890562ff68       0  /content/train/0/00042890562ff68.npy\n",
              "2  0005364cdcb8e5b       0  /content/train/0/0005364cdcb8e5b.npy\n",
              "3  0007a5a46901c56       0  /content/train/0/0007a5a46901c56.npy\n",
              "4  0009283e145448e       0  /content/train/0/0009283e145448e.npy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BOtzCeLTraL"
      },
      "source": [
        "# train_df.to_csv('/content/drive/MyDrive/Colab Notebooks/SETI/input/train_labels_paths.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUBLGe6rTr65"
      },
      "source": [
        "## GridMask Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlvaPfttTsbN"
      },
      "source": [
        "class GridMask(DualTransform):\n",
        "\n",
        "    def __init__(self, num_grid=3, fill_value=0, rotate=0, mode=0, always_apply=False, p=0.5):\n",
        "        super(GridMask, self).__init__(always_apply, p)\n",
        "        if isinstance(num_grid, int):\n",
        "            num_grid = (num_grid, num_grid)\n",
        "        if isinstance(rotate, int):\n",
        "            rotate = (-rotate, rotate)\n",
        "        self.num_grid = num_grid\n",
        "        self.fill_value = fill_value\n",
        "        self.rotate = rotate\n",
        "        self.mode = mode\n",
        "        self.masks = None\n",
        "        self.rand_h_max = []\n",
        "        self.rand_w_max = []\n",
        "\n",
        "    def init_masks(self, height, width):\n",
        "        if self.masks is None:\n",
        "            self.masks = []\n",
        "            n_masks = self.num_grid[1] - self.num_grid[0] + 1\n",
        "            for n, n_g in enumerate(range(self.num_grid[0], self.num_grid[1] + 1, 1)):\n",
        "                grid_h = height / n_g\n",
        "                grid_w = width / n_g\n",
        "                this_mask = np.ones((int((n_g + 1) * grid_h), int((n_g + 1) * grid_w))).astype(np.uint8)\n",
        "                for i in range(n_g + 1):\n",
        "                    for j in range(n_g + 1):\n",
        "                        this_mask[\n",
        "                             int(i * grid_h) : int(i * grid_h + grid_h / 2),\n",
        "                             int(j * grid_w) : int(j * grid_w + grid_w / 2)\n",
        "                        ] = self.fill_value\n",
        "                        if self.mode == 2:\n",
        "                            this_mask[\n",
        "                                 int(i * grid_h + grid_h / 2) : int(i * grid_h + grid_h),\n",
        "                                 int(j * grid_w + grid_w / 2) : int(j * grid_w + grid_w)\n",
        "                            ] = self.fill_value\n",
        "                \n",
        "                if self.mode == 1:\n",
        "                    this_mask = 1 - this_mask\n",
        "\n",
        "                self.masks.append(this_mask)\n",
        "                self.rand_h_max.append(grid_h)\n",
        "                self.rand_w_max.append(grid_w)\n",
        "\n",
        "    def apply(self, image, mask, rand_h, rand_w, angle, **params):\n",
        "        h, w = image.shape[:2]\n",
        "        mask = AF.rotate(mask, angle) if self.rotate[1] > 0 else mask\n",
        "        mask = mask[:,:,np.newaxis] if image.ndim == 3 else mask\n",
        "        image *= mask[rand_h:rand_h+h, rand_w:rand_w+w].astype(image.dtype)\n",
        "        return image\n",
        "\n",
        "    def get_params_dependent_on_targets(self, params):\n",
        "        img = params['image']\n",
        "        height, width = img.shape[:2]\n",
        "        self.init_masks(height, width)\n",
        "\n",
        "        mid = np.random.randint(len(self.masks))\n",
        "        mask = self.masks[mid]\n",
        "        rand_h = np.random.randint(self.rand_h_max[mid])\n",
        "        rand_w = np.random.randint(self.rand_w_max[mid])\n",
        "        angle = np.random.randint(self.rotate[0], self.rotate[1]) if self.rotate[1] > 0 else 0\n",
        "\n",
        "        return {'mask': mask, 'rand_h': rand_h, 'rand_w': rand_w, 'angle': angle}\n",
        "\n",
        "    @property\n",
        "    def targets_as_params(self):\n",
        "        return ['image']\n",
        "\n",
        "    def get_transform_init_args_names(self):\n",
        "        return ('num_grid', 'fill_value', 'rotate', 'mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpSS3-g1T0X4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wo3l7alT5pV"
      },
      "source": [
        "## Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXdczonCT4G1"
      },
      "source": [
        "def get_train_transforms():\n",
        "    return albumentations.Compose(\n",
        "        [\n",
        "            albumentations.Resize(params['size'],params['size']),\n",
        "            albumentations.HorizontalFlip(p=0.5),\n",
        "            albumentations.VerticalFlip(p=0.5),\n",
        "            albumentations.Rotate(limit=180, p=0.7),\n",
        "            albumentations.RandomBrightness(limit=0.6, p=0.5),\n",
        "            albumentations.Cutout(\n",
        "                num_holes=10, max_h_size=12, max_w_size=12,\n",
        "                fill_value=0, always_apply=False, p=0.5\n",
        "            ),\n",
        "            albumentations.ShiftScaleRotate(\n",
        "                shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n",
        "            ),\n",
        "            albumentations.OneOf([\n",
        "                GridMask(num_grid=3, mode=0, rotate=15),\n",
        "                GridMask(num_grid=3, mode=2, rotate=15),\n",
        "                                ], p=0.7),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def get_valid_transforms():\n",
        "    return albumentations.Compose(\n",
        "        [\n",
        "            albumentations.Resize(params['size'],params['size']),\n",
        "            ToTensorV2(p=1.0)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "def get_test_transforms():\n",
        "        return albumentations.Compose(\n",
        "            [\n",
        "                albumentations.Resize(params['size'],params['size']),\n",
        "                ToTensorV2(p=1.0)\n",
        "            ]\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRQghfyAT_2M"
      },
      "source": [
        "## Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9LhXWj9T9lL"
      },
      "source": [
        "class LitDataset(Dataset):\n",
        "    def __init__(self, images_filepaths, targets, transform=None):\n",
        "        self.images_filepaths = images_filepaths\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images_filepaths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_filepath = self.images_filepaths[idx]\n",
        "        image = np.load(image_filepath).astype(np.float32)\n",
        "        image = np.vstack(image).transpose((1, 0))\n",
        "            \n",
        "        if self.transform is not None:\n",
        "            image = self.transform(image=image)[\"image\"]\n",
        "        else:\n",
        "            image = image[np.newaxis,:,:]\n",
        "            image = torch.from_numpy(image).float()\n",
        "        \n",
        "        label = torch.tensor(self.targets[idx]).float()\n",
        "        return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQUdZaJgUEtO"
      },
      "source": [
        "<p p style = \"font-family: garamond; font-size:30px; font-style: normal;background-color: #f6f5f5; color :#6666ff; border-radius: 10px 10px; text-align:center\">Custom Callback for Viewing Predictions in W&B <br> Code Credit <a href = 'https://www.kaggle.com/ayuraj/use-pytorch-lightning-with-weights-and-biases'>Ayush Thakur </a></p>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTwKjcdhUBen"
      },
      "source": [
        "class ImagePredictionLogger(Callback):\n",
        "    def __init__(self, val_samples, num_samples=32):\n",
        "        super().__init__()\n",
        "        self.num_samples = num_samples\n",
        "        self.val_imgs, self.val_labels = val_samples\n",
        "        \n",
        "    def on_validation_epoch_end(self, trainer, pl_module):\n",
        "        val_imgs = self.val_imgs.to(device=pl_module.device)\n",
        "        val_labels = self.val_labels.to(device=pl_module.device)\n",
        "        logits = pl_module(val_imgs)\n",
        "        preds = torch.argmax(logits, -1)\n",
        "        trainer.logger.experiment[1].log({\n",
        "            \"examples\":[wandb.Image(x, caption=f\"Pred:{pred}, Target:{y}\") \n",
        "                           for x, pred, y in zip(val_imgs[:self.num_samples], \n",
        "                                                 preds[:self.num_samples], \n",
        "                                                 val_labels[:self.num_samples])]\n",
        "            }, commit=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_AptYegUOMx"
      },
      "source": [
        "## Ranger Optimizer with Gradient Centralization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JFAN-V3UL-I"
      },
      "source": [
        "# https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer\n",
        "\n",
        "class Ranger(Optimizer):\n",
        "\n",
        "    def __init__(self, params, lr=1e-3,                       # lr\n",
        "                 alpha=0.5, k=6, N_sma_threshhold=5,           # Ranger options\n",
        "                 betas=(.95, 0.999), eps=1e-5, weight_decay=0,  # Adam options\n",
        "                 # Gradient centralization on or off, applied to conv layers only or conv + fc layers\n",
        "                 use_gc=True, gc_conv_only=False\n",
        "                 ):\n",
        "\n",
        "        # parameter checks\n",
        "        if not 0.0 <= alpha <= 1.0:\n",
        "            raise ValueError(f'Invalid slow update rate: {alpha}')\n",
        "        if not 1 <= k:\n",
        "            raise ValueError(f'Invalid lookahead steps: {k}')\n",
        "        if not lr > 0:\n",
        "            raise ValueError(f'Invalid Learning Rate: {lr}')\n",
        "        if not eps > 0:\n",
        "            raise ValueError(f'Invalid eps: {eps}')\n",
        "\n",
        "\n",
        "        # prep defaults and init torch.optim base\n",
        "        defaults = dict(lr=lr, alpha=alpha, k=k, step_counter=0, betas=betas,\n",
        "                        N_sma_threshhold=N_sma_threshhold, eps=eps, weight_decay=weight_decay)\n",
        "        super().__init__(params, defaults)\n",
        "\n",
        "        # adjustable threshold\n",
        "        self.N_sma_threshhold = N_sma_threshhold\n",
        "\n",
        "        # look ahead params\n",
        "\n",
        "        self.alpha = alpha\n",
        "        self.k = k\n",
        "\n",
        "        # radam buffer for state\n",
        "        self.radam_buffer = [[None, None, None] for ind in range(10)]\n",
        "\n",
        "        # gc on or off\n",
        "        self.use_gc = use_gc\n",
        "\n",
        "        # level of gradient centralization\n",
        "        self.gc_gradient_threshold = 3 if gc_conv_only else 1\n",
        "\n",
        "        print(\n",
        "            f\"Ranger optimizer loaded. \\nGradient Centralization usage = {self.use_gc}\")\n",
        "        if (self.use_gc and self.gc_gradient_threshold == 1):\n",
        "            print(f\"GC applied to both conv and fc layers\")\n",
        "        elif (self.use_gc and self.gc_gradient_threshold == 3):\n",
        "            print(f\"GC applied to conv layers only\")\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        print(\"set state called\")\n",
        "        super(Ranger, self).__setstate__(state)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "\n",
        "        # Evaluate averages and grad, update param tensors\n",
        "        for group in self.param_groups:\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data.float()\n",
        "\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError(\n",
        "                        'Ranger optimizer does not support sparse gradients')\n",
        "\n",
        "                p_data_fp32 = p.data.float()\n",
        "\n",
        "                state = self.state[p]  # get state dict for this param\n",
        "\n",
        "                if len(state) == 0:  \n",
        "\n",
        "                    state['step'] = 0\n",
        "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
        "\n",
        "                    # look ahead weight storage now in state dict\n",
        "                    state['slow_buffer'] = torch.empty_like(p.data)\n",
        "                    state['slow_buffer'].copy_(p.data)\n",
        "\n",
        "                else:\n",
        "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
        "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(\n",
        "                        p_data_fp32)\n",
        "\n",
        "                # begin computations\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                # GC operation for Conv layers and FC layers\n",
        "                if grad.dim() > self.gc_gradient_threshold:\n",
        "                    grad.add_(-grad.mean(dim=tuple(range(1, grad.dim())), keepdim=True))\n",
        "\n",
        "                state['step'] += 1\n",
        "\n",
        "                # compute variance mov avg\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                # compute mean moving avg\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "\n",
        "                buffered = self.radam_buffer[int(state['step'] % 10)]\n",
        "\n",
        "                if state['step'] == buffered[0]:\n",
        "                    N_sma, step_size = buffered[1], buffered[2]\n",
        "                else:\n",
        "                    buffered[0] = state['step']\n",
        "                    beta2_t = beta2 ** state['step']\n",
        "                    N_sma_max = 2 / (1 - beta2) - 1\n",
        "                    N_sma = N_sma_max - 2 * \\\n",
        "                        state['step'] * beta2_t / (1 - beta2_t)\n",
        "                    buffered[1] = N_sma\n",
        "                    if N_sma > self.N_sma_threshhold:\n",
        "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (\n",
        "                            N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
        "                    else:\n",
        "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
        "                    buffered[2] = step_size\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    p_data_fp32.add_(-group['weight_decay']\n",
        "                                     * group['lr'], p_data_fp32)\n",
        "\n",
        "                # apply lr\n",
        "                if N_sma > self.N_sma_threshhold:\n",
        "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                    p_data_fp32.addcdiv_(-step_size *\n",
        "                                         group['lr'], exp_avg, denom)\n",
        "                else:\n",
        "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
        "\n",
        "                p.data.copy_(p_data_fp32)\n",
        "\n",
        "                # integrated look ahead...\n",
        "                # we do it at the param level instead of group level\n",
        "                if state['step'] % group['k'] == 0:\n",
        "                    # get access to slow param tensor\n",
        "                    slow_p = state['slow_buffer']\n",
        "                    # (fast weights - slow weights) * alpha\n",
        "                    slow_p.add_(self.alpha, p.data - slow_p)\n",
        "                    # copy interpolated weights to RAdam param tensor\n",
        "                    p.data.copy_(slow_p)\n",
        "\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXqoVGPKUXvE"
      },
      "source": [
        "## Pytorch Lightning DataModule\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbqCJOrCR6Vj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PNAHDqLUVGM"
      },
      "source": [
        "class DataModule(pl.LightningDataModule):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # Config ファイルからの読み込み\n",
        "        self.cfg_dataset = cfg.Data.dataset\n",
        "        self.cfg_augmentation = cfg.Augmentation\n",
        "        self.cfg_dataloader = cfg.Data.dataloader\n",
        "\n",
        "        self.test_df = None\n",
        "        self.train_df = None\n",
        "        self.valid_df = None   \n",
        "\n",
        "\n",
        "    def get_test_df(self):\n",
        "        return pd.read_csv(self.cfg_dataset.test_csv, index_col=0).reset_index(drop = True)\n",
        "\n",
        "    def split_train_valid_df(self):\n",
        "        df = pd.read_csv(self.cfg_dataset.train_csv, index_col=0).reset_index(drop = True)\n",
        "\n",
        "        # Split\n",
        "        skf = StratifiedKFold(n_splits=self.cfg_dataset.nfolds, shuffle=True, random_state=cfg.General.seed)\n",
        "        for n, (train_index, val_index) in enumerate(skf.split(df, df[self.cfg_dataset.target_col])):\n",
        "            df.loc[val_index, \"fold\"] = int(n)\n",
        "        df[\"fold\"] = df[\"fold\"].astype(int)\n",
        "\n",
        "        fold = int(self.cfg_dataset.fold)\n",
        "        train_df = df[df[\"fold\"] != fold].reset_index(drop=True)\n",
        "        valid_df = df[df[\"fold\"] == fold].reset_index(drop=True)\n",
        "        return train_df, valid_df\n",
        "\n",
        "    # 必ず呼び出される関数\n",
        "    def setup(self, stage=False):\n",
        "        self.test_df = self.get_test_df()\n",
        "        train_df, valid_df = self.split_train_valid_df()\n",
        "        self.train_df = train_df\n",
        "        self.valid_df = valid_df\n",
        "        \n",
        "\n",
        "        self.train_dataset = LitDataset(\n",
        "        images_filepaths=self.train_df['image_path'].values,\n",
        "        targets=self.train_df[self.cfg_dataset.target_col].values,\n",
        "        transform=get_train_transforms()\n",
        "            )\n",
        "        \n",
        "        self.val_dataset = LitDataset(\n",
        "        images_filepaths=self.valid_df['image_path'].values,\n",
        "        targets=self.valid_df[self.cfg_dataset.target_col].values,\n",
        "        transform=get_valid_transforms()\n",
        "            )\n",
        "\n",
        "        # self.test_dataset = LitDataset(\n",
        "        # images_filepaths = self.test_df['image_path'].values,\n",
        "        # targets = self.test_df[self.cfg_dataset.target_col].values,\n",
        "        # transform = get_test_transforms()\n",
        "        #     )\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(\n",
        "        self.train_dataset,\n",
        "        batch_size=self.cfg_dataloader.train_batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=self.cfg_dataloader.train_num_workers,\n",
        "        pin_memory=True\n",
        "            )\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(\n",
        "        self.val_dataset,\n",
        "        batch_size=self.cfg_dataloader.valid_batch_size,\n",
        "        shuffle=False,\n",
        "        num_workers=self.cfg_dataloader.valid_num_workers,\n",
        "        pin_memory=True\n",
        "            )\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(\n",
        "        self.test_dataset, batch_size=self.cfg_dataloader.test_batch_size,\n",
        "        shuffle=False, num_workers=self.cfg_dataloader.test_num_workers,\n",
        "        pin_memory=True\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN7LxwAU4lTa"
      },
      "source": [
        "# print(train_df)\n",
        "# LitDataset(\n",
        "#         images_filepaths = train_df['image_path'].values,\n",
        "#         targets=train_df[cfg.Data.dataset.target_col].values,\n",
        "#         # transform=get_train_transforms()\n",
        "#             )[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcybkJzK3e1_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n18KKT0_Ui3w"
      },
      "source": [
        "## Pytorch Lightning Module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YPtccK-LjjP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_xWm4FoLqtb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSCifMltMqJp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNk7GSyFLxMM"
      },
      "source": [
        "# !kaggle competitions download -c seti-breakthrough-listen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbQZvd1WZgvB"
      },
      "source": [
        "# !kaggle datasets download -d snaker/train-7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83rOCGD3an7D"
      },
      "source": [
        "# print(labels_data)\n",
        "# print(output_data.sigmoid())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upYdNKUXXX_u"
      },
      "source": [
        "# labels_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfuzmxfLaGkf"
      },
      "source": [
        "# model = MyLightningModule(cfg)\n",
        "# data_next = next(iter(data_module.train_dataloader()))\n",
        "# x_data  = data_next[0]\n",
        "# y_data = data_next[1]\n",
        "# output_data = model(x_data)\n",
        "# labels_data = y_data.unsqueeze(1)\n",
        "# # print(labels_data)\n",
        "# # print(output_data)\n",
        "# print(nn.BCEWithLogitsLoss()(output_data, labels_data))\n",
        "# print(roc_auc_score(labels_data.detach().cpu(), output_data.sigmoid().detach().cpu()) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdIfT_PFKjNd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Baq2FmJaUiBg"
      },
      "source": [
        "class MyLightningModule(pl.LightningModule):\n",
        "\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        \n",
        "        self.model = timm.create_model(cfg.Model.name, pretrained=cfg.Model.pretrained,\n",
        "                                       in_chans=cfg.Model.input_channels)\n",
        "        n_features = self.model.classifier.in_features\n",
        "        self.model.classifier = nn.Linear(n_features, cfg.Model.out_features, bias=True) \n",
        "        \n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.cfg_optim = cfg.Optimizer\n",
        "        self.cfg_schedule = cfg.Scheduler\n",
        "                \n",
        "    def forward(self, x):\n",
        "        output = self.model(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self(x)\n",
        "        labels = y.unsqueeze(1)\n",
        "        loss = self.criterion(output, labels)\n",
        "        \n",
        "        try:\n",
        "            auc=roc_auc_score(labels.detach().cpu(), output.sigmoid().detach().cpu()) \n",
        "\n",
        "            self.log(\"auc\", auc, on_step= True, prog_bar=True, logger=True)\n",
        "            self.log(\"Train Loss\", loss, on_step= True,prog_bar=True, logger=True)\n",
        "        except:\n",
        "            pass\n",
        "        return {\"loss\": loss, \"predictions\": output, \"labels\": labels}\n",
        "\n",
        "    def training_epoch_end(self, outputs):\n",
        "\n",
        "        preds = []\n",
        "        labels = []\n",
        "        \n",
        "        for output in outputs:\n",
        "            \n",
        "            preds += output['predictions']\n",
        "            labels += output['labels']\n",
        "\n",
        "        labels = torch.stack(labels)\n",
        "        preds = torch.stack(preds)\n",
        "        # try:\n",
        "        #     train_auc=roc_auc_score(labels.detach().cpu(), preds.sigmoid().detach().cpu())\n",
        "        #     self.log(\"mean_train_auc\", train_auc, prog_bar=True, logger=True)\n",
        "        # except:\n",
        "        #     pass\n",
        "        train_auc=roc_auc_score(labels.detach().cpu(), preds.sigmoid().detach().cpu())\n",
        "        self.log(\"mean_train_auc\", train_auc, prog_bar=True, logger=True)        \n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        x, y = batch\n",
        "        output = self(x)\n",
        "        labels = y.unsqueeze(1)\n",
        "        loss = self.criterion(output, labels)\n",
        "        self.log('val_loss', loss, on_step= True, prog_bar=True, logger=True)\n",
        "        return {\"predictions\": output, \"labels\": labels}\n",
        "      \n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "\n",
        "        preds = []\n",
        "        labels = []\n",
        "        \n",
        "        for output in outputs:\n",
        "            preds += output['predictions']\n",
        "            labels += output['labels']\n",
        "\n",
        "        labels = torch.stack(labels)\n",
        "        preds = torch.stack(preds)\n",
        "        # try:\n",
        "        #     val_auc=roc_auc_score(labels.detach().cpu(), preds.sigmoid().detach().cpu())\n",
        "        #     self.log(\"val_auc\", val_auc, prog_bar=True, logger=True)\n",
        "        # except:\n",
        "        #     pass    \n",
        "        val_auc=roc_auc_score(labels.detach().cpu(), preds.sigmoid().detach().cpu())\n",
        "        self.log(\"val_auc\", val_auc, prog_bar=True, logger=True)    \n",
        "\n",
        "        \n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        x = batch        \n",
        "        output = self(x).sigmoid()\n",
        "        return output   \n",
        "\n",
        "    def configure_optimizers(self):\n",
        "\n",
        "        optimizer = Ranger(self.parameters(), lr = self.cfg_optim.lr)\n",
        "\n",
        "        scheduler = CosineAnnealingLR(optimizer,\n",
        "                              T_max=self.cfg_schedule.T_max,\n",
        "                              eta_min=self.cfg_schedule.min_lr,\n",
        "                              last_epoch=-1)\n",
        "\n",
        "        return dict(\n",
        "          optimizer=optimizer,\n",
        "          lr_scheduler=scheduler\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSZPFxE_fbEO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxdgqrpWUslu"
      },
      "source": [
        "## Pytorch Lightning Trainer\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0UALy97rjxR"
      },
      "source": [
        "# !pip uninstall pytorch-lightning wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pE_mE2IyqXJ4"
      },
      "source": [
        "# !pip install -qqq pytorch-lightning wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "he2oDtXtsY-z"
      },
      "source": [
        "# ! pip install --quiet \"scikit-learn\" \"datasets\" \"scipy\" \"torchmetrics\" \"transformers\" \"torch==1.9\" \"pytorch-lightning>=1.3\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BDydIK6hAyb"
      },
      "source": [
        "# from pytorch_lightning.plugins.training_type import DDPPlugin"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skNFcrmUqtiv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI4lU8cYUoYJ"
      },
      "source": [
        "fold = cfg.Data.dataset.fold\n",
        "cfg.General.debug = True\n",
        "print(f\"{'='*38} Fold: {fold} {'='*38}\")\n",
        "\n",
        "logger = CSVLogger(save_dir=cfg.General.save_dir, name=cfg.General.compe_name +'_' +cfg.General.project + f\"fold_{fold}\")\n",
        "wandb_logger = WandbLogger(name=cfg.General.compe_name +'_' +cfg.General.project + f\"_{fold}\", project=cfg.General.project, offline = False)\n",
        "tb_logger = pl_loggers.TensorBoardLogger(cfg.General.tb_logger_dir)\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath=\"checkpoints\",\n",
        "    filename=cfg.General.compe_name +'_' +cfg.General.project + \"_{epoch:02d}-{fold}-{val_auc:.3f}\",\n",
        "    save_top_k=3,\n",
        "    verbose=True,\n",
        "    monitor=\"val_auc\",\n",
        "    mode=\"max\"\n",
        ")\n",
        "\n",
        "\n",
        "model = MyLightningModule(cfg)\n",
        "data_module = DataModule(cfg)\n",
        "data_module.setup()\n",
        "val_samples = next(iter(data_module.val_dataloader()))\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_auc',mode=\"max\", patience=2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# \n",
        "trainer = pl.Trainer(\n",
        "    gpus= cfg.General.gpus,\n",
        "    checkpoint_callback=checkpoint_callback,\n",
        "    callbacks=[early_stopping_callback,\n",
        "                    ImagePredictionLogger(val_samples)],\n",
        "    max_epochs=cfg.General.epoch,\n",
        "    precision=16 if cfg.General.fp16 else 32,\n",
        "    progress_bar_refresh_rate=1,\n",
        "    limit_train_batches = 0.005 if cfg.General.debug else 1.0,\n",
        "    limit_val_batches = 0.005 if cfg.General.debug else 1.0,\n",
        "    logger=[logger, wandb_logger, tb_logger],\n",
        "    # logger=wandb_logger,\n",
        "    # For fast https://pytorch-lightning.readthedocs.io/en/1.3.3/benchmarking/performance.html#\n",
        "    # plugins=DDPPlugin(find_unused_parameters=False),\n",
        ")\n",
        "\n",
        "trainer.fit(model, data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWKZk0Q2U4xy"
      },
      "source": [
        "[このコード](https://www.kaggle.com/ryonasuda/pytorch-lightning-grid-mask-ranger-opt-w-b/edit)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsOUphirU4O1"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMe8VU3bucek"
      },
      "source": [
        "pl.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rxCVEK8Na37x"
      },
      "source": [
        "cfg.General.gpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBJnYFo5d3Ln"
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./lightning_log/default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV3brW9qfPq7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}